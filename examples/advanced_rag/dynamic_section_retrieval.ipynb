{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4b2c37d-3b5a-47aa-95b9-d28e0bc83f77",
      "metadata": {
        "id": "f4b2c37d-3b5a-47aa-95b9-d28e0bc83f77"
      },
      "source": [
        "# Dynamic Section Retrieval with LlamaParse\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/run-llama/llamacloud-demo/blob/main/examples/advanced_rag/dynamic_section_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook showcases a concept called \"dynamic section retrieval\".\n",
        "\n",
        "A common problem with naive RAG approaches is that each document is hierarchically organized by section, but standard chunking/retrieval searches for chunks that can be fragments of the entire section and miss out on relevant context.\n",
        "\n",
        "Dynamic section retrieval takes into account entire contiguous sections as metadata during retrieval, avoiding the problem of retrieving section fragments.\n",
        "1. First, tag chunks of a long document with the sections they correspond to, through structured extraction.\n",
        "2. Do two-pass retrieval. After initial semantic search, dynamically pull in the entire section through metadata filtering.\n",
        "\n",
        "![](https://github.com/run-llama/llama_parse/blob/main/examples/advanced_rag/dynamic_section_retrieval_img.png?raw=1)\n",
        "\n",
        "This helps provide a solution to the common chunking problem of retrieving chunks that are only subsets of the entire section you're meant to retrieve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4f707a-c7b5-473f-b4a6-881e2245e82d",
      "metadata": {
        "id": "2e4f707a-c7b5-473f-b4a6-881e2245e82d"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install core packages and download relevant files. Here we load some popular ICLR 2024 papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "71bd0714-324f-48b3-8a93-72c6c3a10b53",
      "metadata": {
        "id": "71bd0714-324f-48b3-8a93-72c6c3a10b53"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9aa458bc-bc8d-46fe-9a57-021dd8d9e525",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9aa458bc-bc8d-46fe-9a57-021dd8d9e525",
        "outputId": "6294f46a-fbcb-4847-82f4-33da9336da5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.12.2)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.54.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-index-core in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core) (1.2.2)\n",
            "Requirement already satisfied: llama-parse in /usr/local/lib/python3.10/dist-packages (0.5.16)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from llama-parse) (8.1.7)\n",
            "Requirement already satisfied: llama-index-core>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-parse) (0.12.2)\n",
            "Requirement already satisfied: pydantic!=2.10 in /usr/local/lib/python3.10/dist-packages (from llama-parse) (2.9.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (11.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.10->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.10->llama-parse) (2.23.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (4.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core>=0.11.0->llama-parse) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-core\n",
        "!pip install llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79821400-caaf-42f1-99d8-74c184c19e29",
      "metadata": {
        "id": "79821400-caaf-42f1-99d8-74c184c19e29"
      },
      "outputs": [],
      "source": [
        "# NOTE: uncomment more papers if you want to do research over a larger subset of docs\n",
        "\n",
        "urls = [\n",
        "    # \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    # \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    # \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
        "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "    # \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
        "    # \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
        "    # \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
        "    # \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
        "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
        "    # \"https://openreview.net/pdf?id=TpD2aG1h0D\",\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    # \"metagpt.pdf\",\n",
        "    # \"longlora.pdf\",\n",
        "    # \"loftq.pdf\",\n",
        "    \"swebench.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "    # \"zipformer.pdf\",\n",
        "    # \"values.pdf\",\n",
        "    # \"finetune_fair_diffusion.pdf\",\n",
        "    # \"knowledge_card.pdf\",\n",
        "    \"metra.pdf\",\n",
        "    # \"vr_mcl.pdf\",\n",
        "]\n",
        "\n",
        "data_dir = \"iclr_docs\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"iclr_docs\"\n",
        "!mkdir \"{data_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3tQDT3x1iF_",
        "outputId": "7ff8d0c1-21fe-4b4c-d75d-b6fad0994f68"
      },
      "id": "A3tQDT3x1iF_",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘iclr_docs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80137d15-f22b-47eb-adce-ac295ced7e71",
      "metadata": {
        "collapsed": true,
        "id": "80137d15-f22b-47eb-adce-ac295ced7e71",
        "outputId": "ae5147ba-ea79-459c-aae9-2eefcebf0b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: iclr_docs: File exists\n",
            "--2024-11-10 16:18:56--  https://openreview.net/pdf?id=VTF8yNQM66\n",
            "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
            "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2680380 (2.6M) [application/pdf]\n",
            "Saving to: ‘iclr_docs/swebench.pdf’\n",
            "\n",
            "iclr_docs/swebench. 100%[===================>]   2.56M  7.22MB/s    in 0.4s    \n",
            "\n",
            "2024-11-10 16:18:57 (7.22 MB/s) - ‘iclr_docs/swebench.pdf’ saved [2680380/2680380]\n",
            "\n",
            "--2024-11-10 16:18:57--  https://openreview.net/pdf?id=hSyW5go0v8\n",
            "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
            "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244749 (1.2M) [application/pdf]\n",
            "Saving to: ‘iclr_docs/selfrag.pdf’\n",
            "\n",
            "iclr_docs/selfrag.p 100%[===================>]   1.19M  4.21MB/s    in 0.3s    \n",
            "\n",
            "2024-11-10 16:18:58 (4.21 MB/s) - ‘iclr_docs/selfrag.pdf’ saved [1244749/1244749]\n",
            "\n",
            "--2024-11-10 16:18:58--  https://openreview.net/pdf?id=c5pwL0Soay\n",
            "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
            "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4775879 (4.6M) [application/pdf]\n",
            "Saving to: ‘iclr_docs/metra.pdf’\n",
            "\n",
            "iclr_docs/metra.pdf 100%[===================>]   4.55M  4.06MB/s    in 1.1s    \n",
            "\n",
            "2024-11-10 16:19:00 (4.06 MB/s) - ‘iclr_docs/metra.pdf’ saved [4775879/4775879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir \"{data_dir}\"\n",
        "for url, paper in zip(urls, papers):\n",
        "    !wget \"{url}\" -O \"{data_dir}/{paper}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "974ce0a5-931a-4c1f-b8f3-af670c08eb0f",
      "metadata": {
        "id": "974ce0a5-931a-4c1f-b8f3-af670c08eb0f"
      },
      "source": [
        "#### Define LLM and Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U llama-index-llms-azure-inference\n",
        "!pip install -U llama-index-embeddings-azure-inference"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8o4G_27yWFv",
        "outputId": "59074f89-0fd3-4d97-ea56-e82c6766f0e7"
      },
      "id": "-8o4G_27yWFv",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-llms-azure-inference in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-inference) (3.11.2)\n",
            "Requirement already satisfied: azure-ai-inference>=1.0.0b5 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-inference) (1.0.0b6)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-inference) (1.19.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-inference) (0.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-llms-azure-inference) (4.0.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-llms-azure-inference) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-llms-azure-inference) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-llms-azure-inference) (4.12.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (43.0.3)\n",
            "Requirement already satisfied: msal>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (1.31.1)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (1.2.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (4.66.6)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.16.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-ai-inference>=1.0.0b5->llama-index-llms-azure-inference) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (2.10.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (2.10.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (0.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-inference) (2.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (24.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-azure-inference) (1.2.2)\n",
            "Requirement already satisfied: llama-index-embeddings-azure-inference in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-inference) (3.11.2)\n",
            "Requirement already satisfied: azure-ai-inference>=1.0.0b5 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-inference) (1.0.0b6)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-inference) (1.19.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-inference) (0.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.0->llama-index-embeddings-azure-inference) (4.0.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-embeddings-azure-inference) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-embeddings-azure-inference) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference>=1.0.0b5->llama-index-embeddings-azure-inference) (4.12.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (43.0.3)\n",
            "Requirement already satisfied: msal>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (1.31.1)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (1.2.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (4.66.6)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.16.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-ai-inference>=1.0.0b5->llama-index-embeddings-azure-inference) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (2.10.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (2.10.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (0.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-embeddings-azure-inference) (2.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (24.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-azure-inference) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.azure_inference import AzureAICompletionsModel\n",
        "from llama_index.embeddings.azure_inference import AzureAIEmbeddingsModel"
      ],
      "metadata": {
        "id": "7vjPHsy9ya1H"
      },
      "id": "7vjPHsy9ya1H",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI"
      ],
      "metadata": {
        "id": "DLU7kMqyCTMR"
      },
      "id": "DLU7kMqyCTMR",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = AzureOpenAI(\n",
        "  api_key = \"EcpnZTlxYcDNtgfui7mWYS0JeTWJPlNXJEaILe2fwF6dftfTBqYLJQQJ99ALACYeBjFXJ3w3AAAAACOGXsqG\",\n",
        "  api_version = \"2024-02-01\",\n",
        "  azure_endpoint =\"https://ai-depoc1aihub1643128651037.cognitiveservices.azure.com/\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input = \"Your text string goes here\",\n",
        "    model= \"text-embedding-3-large\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "OSJ_36QHCXzB"
      },
      "id": "OSJ_36QHCXzB",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureAICompletionsModel(\n",
        "    endpoint=\"https://ai-depoc1aihub1643128651037.openai.azure.com/openai/deployments/gpt-4o\",\n",
        "    credential=\"EcpnZTlxYcDNtgfui7mWYS0JeTWJPlNXJEaILe2fwF6dftfTBqYLJQQJ99ALACYeBjFXJ3w3AAAAACOGXsqG\",\n",
        "    api_version=\"2024-08-01-preview\",\n",
        ")"
      ],
      "metadata": {
        "id": "xv3ddXb_ynlf"
      },
      "id": "xv3ddXb_ynlf",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = AzureAIEmbeddingsModel(\n",
        "    endpoint=\"https://ai-depoc1aihub1643128651037.openai.azure.com/openai/deployments/text-embedding-3-large\",\n",
        "    credential=\"EcpnZTlxYcDNtgfui7mWYS0JeTWJPlNXJEaILe2fwF6dftfTBqYLJQQJ99ALACYeBjFXJ3w3AAAAACOGXsqG\",\n",
        "    model_name=\"text-embedding-3-large\",\n",
        ")"
      ],
      "metadata": {
        "id": "Ut8t1H4bysOm"
      },
      "id": "Ut8t1H4bysOm",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings"
      ],
      "metadata": {
        "id": "U-JRfQK1zNme"
      },
      "id": "U-JRfQK1zNme",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "RviQ7kRJzI3c"
      },
      "id": "RviQ7kRJzI3c",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a05e99-56e2-4db9-baae-f9401100dcc3",
      "metadata": {
        "id": "75a05e99-56e2-4db9-baae-f9401100dcc3"
      },
      "outputs": [],
      "source": [
        "#from llama_index.core import Settings\n",
        "#from llama_index.llms.openai import OpenAI\n",
        "#from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "#\n",
        "#embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "#llm = OpenAI(model=\"gpt-4o\")\n",
        "#\n",
        "#Settings.embed_model = embed_model\n",
        "#Settings.llm = llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f16859f-c69e-4edf-acb6-0a5a0784275a",
      "metadata": {
        "id": "2f16859f-c69e-4edf-acb6-0a5a0784275a"
      },
      "source": [
        "#### Parse Documents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "MqSeOnUm2WfD"
      },
      "id": "MqSeOnUm2WfD",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = (\n",
        "    os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
        "    if \"LLAMA_CLOUD_API_KEY\" in os.environ\n",
        "    else getpass(\"LLAMA CLOUD API key: \")\n",
        ")"
      ],
      "metadata": {
        "id": "-FqjMXYZ16tl"
      },
      "id": "-FqjMXYZ16tl",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "d6cd2cc9-673f-4f53-81fb-cc990950d345",
      "metadata": {
        "id": "d6cd2cc9-673f-4f53-81fb-cc990950d345"
      },
      "outputs": [],
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "parser = LlamaParse(result_type=\"markdown\",target_pages=\"0,1,2,3,4,5,6,7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers = [\n",
        "    # \"metagpt.pdf\",\n",
        "    # \"longlora.pdf\",\n",
        "    # \"loftq.pdf\",\n",
        "    \"1.3.2.6.2_Honeywell Long Term Contract_C14.pdf\",\n",
        "    #\"selfrag.pdf\",\n",
        "    # \"zipformer.pdf\",\n",
        "    # \"values.pdf\",\n",
        "    # \"finetune_fair_diffusion.pdf\",\n",
        "    # \"knowledge_card.pdf\",\n",
        "    #\"metra.pdf\",\n",
        "    # \"vr_mcl.pdf\",\n",
        "]"
      ],
      "metadata": {
        "id": "zRm1UDeO2yhF"
      },
      "id": "zRm1UDeO2yhF",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "f9d6f0e8-323e-4786-a4a8-e393441ecd61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d6f0e8-323e-4786-a4a8-e393441ecd61",
        "outputId": "30b8d6d1-fd52-405d-eb39-47ba5f61a4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id e98d35b9-b418-4cfd-b4f4-de7d7be505f5\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paper_dicts = {}\n",
        "\n",
        "for paper_path in papers:\n",
        "    paper_base = Path(paper_path).stem\n",
        "    full_paper_path = str(Path(data_dir) / paper_path)\n",
        "    md_json_objs = parser.get_json_result(full_paper_path)\n",
        "    json_dicts = md_json_objs[0][\"pages\"]\n",
        "    paper_dicts[paper_path] = {\n",
        "        \"paper_path\": full_paper_path,\n",
        "        \"json_dicts\": json_dicts,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d52878b-aabf-418e-a4c7-9903a77dd8c8",
      "metadata": {
        "id": "2d52878b-aabf-418e-a4c7-9903a77dd8c8"
      },
      "source": [
        "#### Get Text Nodes\n",
        "\n",
        "Convert the dictionary above into TextNode objects that we can put into a vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "18c24174-05ce-417f-8dd2-79c3f375db03",
      "metadata": {
        "id": "18c24174-05ce-417f-8dd2-79c3f375db03"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.schema import TextNode\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "8e331dfe-a627-4e23-8c57-70ab1d9342e4",
      "metadata": {
        "id": "8e331dfe-a627-4e23-8c57-70ab1d9342e4"
      },
      "outputs": [],
      "source": [
        "# NOTE: these are utility functions to sort the dumped images by the page number\n",
        "# (they are formatted like \"{uuid}-{page_num}.jpg\"\n",
        "import re\n",
        "\n",
        "\n",
        "def get_page_number(file_name):\n",
        "    match = re.search(r\"-page-(\\d+)\\.jpg$\", str(file_name))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return 0\n",
        "\n",
        "\n",
        "def _get_sorted_image_files(image_dir):\n",
        "    \"\"\"Get image files sorted by page.\"\"\"\n",
        "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file()]\n",
        "    sorted_files = sorted(raw_files, key=get_page_number)\n",
        "    return sorted_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "346fe5ef-171e-4a54-9084-7a7805103a13",
      "metadata": {
        "id": "346fe5ef-171e-4a54-9084-7a7805103a13"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# attach image metadata to the text nodes\n",
        "def get_text_nodes(json_dicts, paper_path):\n",
        "    \"\"\"Split docs into nodes, by separator.\"\"\"\n",
        "    nodes = []\n",
        "\n",
        "    md_texts = [d[\"md\"] for d in json_dicts]\n",
        "\n",
        "    for idx, md_text in enumerate(md_texts):\n",
        "        chunk_metadata = {\n",
        "            \"page_num\": idx + 1,\n",
        "            \"paper_path\": paper_path,\n",
        "        }\n",
        "        node = TextNode(\n",
        "            text=md_text,\n",
        "            metadata=chunk_metadata,\n",
        "        )\n",
        "        nodes.append(node)\n",
        "\n",
        "    return nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "f591669c-5a8e-491d-9cef-0b754abbf26f",
      "metadata": {
        "id": "f591669c-5a8e-491d-9cef-0b754abbf26f"
      },
      "outputs": [],
      "source": [
        "# this will combine all nodes from all papers into a single list\n",
        "all_text_nodes = []\n",
        "text_nodes_dict = {}\n",
        "for paper_path, paper_dict in paper_dicts.items():\n",
        "    json_dicts = paper_dict[\"json_dicts\"]\n",
        "    text_nodes = get_text_nodes(json_dicts, paper_dict[\"paper_path\"])\n",
        "    all_text_nodes.extend(text_nodes)\n",
        "    text_nodes_dict[paper_path] = text_nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b25f253-3aa0-4689-be6e-d0c722b8b48c",
      "metadata": {
        "id": "3b25f253-3aa0-4689-be6e-d0c722b8b48c"
      },
      "source": [
        "## Add Section Metadata\n",
        "\n",
        "The first step is to extract out a map of all sections from the text of each document. We create a workflow that extracts out if a section heading exists on each page, and merges it together into a combined list. We then run a reflection step to review/correct the extracted sections to make sure everything is correct.\n",
        "\n",
        "Once we have a map of all the sections and the page numbers they start at, we can add the appropriate section ID as metadata to each chunk."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8fdb689-cc94-4da2-ba12-9267e8ee8623",
      "metadata": {
        "id": "d8fdb689-cc94-4da2-ba12-9267e8ee8623"
      },
      "source": [
        "#### Define Section Schema to Extract Into\n",
        "\n",
        "Here we define the output schema which allows us to extract out the section metadata from each section of the document. This will give us a full table of contents of each section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "66358783-1d7f-489d-a85b-35bcb9620912",
      "metadata": {
        "id": "66358783-1d7f-489d-a85b-35bcb9620912"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "class SectionOutput(BaseModel):\n",
        "    \"\"\"The metadata for a given section. Includes the section name, title, page that it starts on, and more.\"\"\"\n",
        "\n",
        "    section_name: str = Field(\n",
        "        ..., description=\"The current section number (e.g. section_name='3.2')\"\n",
        "    )\n",
        "    section_title: str = Field(\n",
        "        ...,\n",
        "        description=\"The current section title associated with the number (e.g. section_title='Experimental Results')\",\n",
        "    )\n",
        "\n",
        "    start_page_number: int = Field(..., description=\"The start page number.\")\n",
        "    is_subsection: bool = Field(\n",
        "        ...,\n",
        "        description=\"True if it's a subsection (e.g. Section 3.2). False if it's not a subsection (e.g. Section 3)\",\n",
        "    )\n",
        "    description: Optional[str] = Field(\n",
        "        None,\n",
        "        description=\"The extracted line from the source text that indicates this is a relevant section.\",\n",
        "    )\n",
        "\n",
        "    def get_section_id(self):\n",
        "        \"\"\"Get section id.\"\"\"\n",
        "        return f\"{self.section_name}: {self.section_title}\"\n",
        "\n",
        "\n",
        "class SectionsOutput(BaseModel):\n",
        "    \"\"\"A list of all sections.\"\"\"\n",
        "\n",
        "    sections: List[SectionOutput]\n",
        "\n",
        "\n",
        "class ValidSections(BaseModel):\n",
        "    \"\"\"A list of indexes, each corresponding to a valid section.\"\"\"\n",
        "\n",
        "    valid_indexes: List[int] = Field(\n",
        "        \"List of valid section indexes. Do NOT include sections to remove.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff90c77-f92e-4c5e-a441-70f81adb68fb",
      "metadata": {
        "id": "bff90c77-f92e-4c5e-a441-70f81adb68fb"
      },
      "source": [
        "#### Extract into Section Outputs\n",
        "\n",
        "Use LlamaIndex structured output capabilities to iterate through each page and extract out relevant section metadata. Note: some pages may contain no section metadata (there are no sections that begin on that page)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "dcfcd3a6-4739-4624-a6ed-678e41119575",
      "metadata": {
        "id": "dcfcd3a6-4739-4624-a6ed-678e41119575"
      },
      "outputs": [],
      "source": [
        "#from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.prompts import ChatPromptTemplate, ChatMessage\n",
        "from llama_index.core.llms import LLM\n",
        "from llama_index.core.async_utils import run_jobs, asyncio_run\n",
        "import json\n",
        "\n",
        "\n",
        "async def aget_sections(\n",
        "    doc_text: str, llm: Optional[LLM] = None\n",
        ") -> List[SectionOutput]:\n",
        "    \"\"\"Get extracted sections from a provided text.\"\"\"\n",
        "\n",
        "    system_prompt = \"\"\"\\\n",
        "    You are an AI document assistant tasked with extracting out section metadata from a document text.\n",
        "\n",
        "- You should ONLY extract out metadata if the document text contains the beginning of a section.\n",
        "- The metadata schema is listed below - you should extract out the section_name, section_title, start page number, description.\n",
        "- A valid section MUST begin with a hashtag (#) and have a number (e.g. \"1 Introduction\" or \"Section 1 Introduction\"). \\\n",
        "Note: Not all hashtag (#) lines are valid sections.\n",
        "\n",
        "- You can extract out multiple section metadata if there are multiple sections on the page.\n",
        "- If there are no sections that begin in this document text, do NOT extract out any sections.\n",
        "- A valid section MUST be clearly delineated in the document text. Do NOT extract out a section if it is mentioned, \\\n",
        "but is not actually the start of a section in the document text.\n",
        "- A Figure or Table does NOT count as a section.\n",
        "\n",
        "    The user will give the document text below.\n",
        "\n",
        "    \"\"\"\n",
        "    llm = llm\n",
        "    #or OpenAI(model=\"gpt-4o\")\n",
        "\n",
        "    chat_template = ChatPromptTemplate(\n",
        "        [\n",
        "            ChatMessage.from_str(system_prompt, \"system\"),\n",
        "            ChatMessage.from_str(\"Document text: {doc_text}\", \"user\"),\n",
        "        ]\n",
        "    )\n",
        "    result = await llm.astructured_predict(\n",
        "        SectionsOutput, chat_template, doc_text=doc_text\n",
        "    )\n",
        "    return result.sections\n",
        "\n",
        "\n",
        "async def arefine_sections(\n",
        "    sections: List[SectionOutput], llm: Optional[LLM] = None\n",
        ") -> List[SectionOutput]:\n",
        "    \"\"\"Refine sections based on extracted text.\"\"\"\n",
        "\n",
        "    system_prompt = \"\"\"\\\n",
        "    You are an AI review assistant tasked with reviewing and correcting another agent's work in extracting sections from a document.\n",
        "\n",
        "    Below is the list of sections with indexes. The sections may be incorrect in the following manner:\n",
        "    - There may be false positive sections - some sections may be wrongly extracted - you can tell by the sequential order of the rest of the sections\n",
        "    - Some sections may be incorrectly marked as subsections and vice-versa\n",
        "    - You can use the description which contains extracted text from the source document to see if it actually qualifies as a section.\n",
        "\n",
        "    Given this, return the list of indexes that are valid. Do NOT include the indexes to be removed.\n",
        "\n",
        "    \"\"\"\n",
        "    llm = llm\n",
        "    #or OpenAI(model=\"gpt-4o\")\n",
        "\n",
        "    chat_template = ChatPromptTemplate(\n",
        "        [\n",
        "            ChatMessage.from_str(system_prompt, \"system\"),\n",
        "            ChatMessage.from_str(\"Sections in text:\\n\\n{sections}\", \"user\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    section_texts = \"\\n\".join(\n",
        "        [f\"{idx}: {json.dumps(s.dict())}\" for idx, s in enumerate(sections)]\n",
        "    )\n",
        "\n",
        "    result = await llm.astructured_predict(\n",
        "        ValidSections, chat_template, sections=section_texts\n",
        "    )\n",
        "    valid_indexes = result.valid_indexes\n",
        "\n",
        "    new_sections = [s for idx, s in enumerate(sections) if idx in valid_indexes]\n",
        "    return new_sections\n",
        "\n",
        "\n",
        "async def acreate_sections(text_nodes_dict):\n",
        "    sections_dict = {}\n",
        "    for paper_path, text_nodes in text_nodes_dict.items():\n",
        "        all_sections = []\n",
        "\n",
        "        tasks = [aget_sections(n.get_content(metadata_mode=\"all\"),llm) for n in text_nodes]\n",
        "\n",
        "        async_results = await run_jobs(tasks, workers=8, show_progress=True)\n",
        "        all_sections = [s for r in async_results for s in r]\n",
        "\n",
        "        all_sections = await arefine_sections(all_sections,llm)\n",
        "        sections_dict[paper_path] = all_sections\n",
        "    return sections_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(text_nodes_dict)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LDO2R4cBk5ad",
        "outputId": "e5334ab4-5c15-4aa8-e5b6-cf86ef74f9e9"
      },
      "id": "LDO2R4cBk5ad",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'1.3.2.6.2_Honeywell Long Term Contract_C14.pdf': [TextNode(id_='8752129e-0eb5-4287-98a3-42e9ec7e2291', embedding=None, metadata={'page_num': 1, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# THE POWER OF CONNECTED\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\nBETWEEN HONEYWELL INTERNATIONAL INC.\\n\\nAND UNITED AVIONICS INC.\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT: DEF10177\\n\\nPROGRAM: TIGER III\\n\\nPRIME CONTRACT NUMBER: W56HZV-20-D-0062\\n\\nPERIOD OF PERFORMANCE: 10/1/2020 - 9/30/2025\\n\\nCONTRACT TYPE: FFP\\n\\nDS PN Honeywell (v01-2021) Stand-Alone Government Program Contract\\n\\nHoneywell Confidential', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='fa24356a-e97d-445d-948b-5af71e1eff06', embedding=None, metadata={'page_num': 2, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\n# TABLE OF CONTENTS\\n\\n|1.|DEFINITIONS|3|\\n|---|---|---|\\n|2.|SCOPE|33|\\n|2.3|CONTRACT TERM|33|\\n|4.|DEFENSE PRIORITIES AND ALLOCATIONS SYSTEM (DPAS) RATING|33|\\n|5.|NON-MILITARY END USER AND END USE CERTIFICATION (MEU RULE)|33|\\n|6.|NOTICES AND POINTS OF CONTACT|73|\\n|6.7|ORDER OF PRECEDENCE|4|\\n|7.|RESERVED|4|\\n|8.|PURCHASE COMMITMENT|4|\\n|9.|PROGRAM MANAGEMENT|4|\\n|10.|RESERVED|4|\\n|12.|PRICE|4|\\n|13.|THIRD PARTY COMMUNICATIONS|5|\\n|14.|DATA PRIVACY|5|\\n|15.|ENTIRE AGREEMENT|5|\\n|16.|ENTIRE AGREEMENT|6|\\n\\n# ATTACHMENT 1\\n\\nGOODS, DELIVERABLES, NON-RECURRING ENGINEERING, AND PRICES\\n\\n# ATTACHMENT 2\\n\\nPRIME CONTRACT TERMS AND CONDITIONS\\n\\n# EXHIBIT\\n\\nHONEYWELL'S SECURITY TERMS AND CONDITIONS FOR SUPPLIERS\\n\\nPage 2\\n\\nHoneywell RN~s\\n\\n(v01-2021) Stand-Alone Government Program Contract\\n\\nHoneywell Confidential\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='89c87a64-0c7b-4275-91c4-4786c744dd46', embedding=None, metadata={'page_num': 3, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\nThis Stand-Alone Government Program Contract (Contract) is entered into and effective as of March 1, 2021 (Effective Date) by and between Honeywell International Inc., a Delaware corporation, acting through its Aerospace strategic business group, having an office and place of business at 1300 W Warner Rd, Tempe, AZ 85284 (Honeywell) and United Avionics Inc., a Connecticut corporation, having an address of 38 Great Hill Rd, Naugatuck, CT 06770 (Supplier): Supplier and Honeywell are sometimes referred to separately as a \"Party\" and together as the \"Parties\".\\n\\nHoneywell has launched the Program defined herein, Supplier desires to participate in such Program, and Honeywell has selected Supplier, subject to the terms and conditions herein, to participate in the Program.\\n\\nThe Parties agree as follows.\\n\\n# 1. DEFINITIONS\\n\\n\"Authorized Representative\" means the individual designated by each Party having primary authority and responsibility for interacting with the other Party regarding this Contract:\\n\\n\"Deliverables\" mean the documents, reports, material, prototypes, information, data, Computer Software, Source Code, and other items (if any, but excluding Goods) specified in this Contract and its attachments to be delivered to Honeywell by or on behalf of Supplier;\\n\\n\"Goods\" mean products and services as applicable and to the extent described in this Contract and its attachments.\\n\\n\"Period of Performance\" is October 1, 2020 to September 30, 2025.\\n\\n\"Personal Data\" is any information relating to an identified or identifiable natural person (an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person), or as that term (or similar variants) may otherwise be defined in applicable data protection, privacy, breach notification, or data security laws or regulations (\"Applicable Data Privacy Laws\").\\n\\n\"Program\" means the TIGER III program in support of U.S. Army Prime Contract W56HZV-20-D-0062.\\n\\n\"Purchase Order\" means an order issued by Honeywell under this Contract identifying the Goods and Deliverables to be purchased, purchase price, delivery dates, and other information required under this Contract.\\n\\n# 2. SCOPE\\n\\nThis Contract is for the supply of Goods to the extent described in this Contract and its attachments, attached and incorporated herein, in support of the Program.\\n\\n# 3. CONTRACT TERM\\n\\nThis Contract commences on the Effective Date and will remain in effect through the Period of Performance unless extended by mutual written agreement between the Parties or terminated (\"Contract Term\" or \"Term\"): This Contract will govern any Purchase Order issued prior to the expiration or termination of this Contract. Pricing for all Purchase Orders issued during the term of this Contract will be in accordance with the pricing stipulated in this Contract; even if the delivery dates for the Goods and Deliverables fall outside the Contract Term.\\n\\n# 4. DEFENSE PRIORITIES AND ALLOCATIONS SYSTEM (DPAS) RATING\\n\\nThis Contract is rated DO-A4.\\n\\n# 5. NON-MILITARY END USER AND END USE CERTIFICATION (MEU RULE)\\n\\nIn order to satisfy U.S. export control laws, the Supplier confirms that it is not an entity that meets the definition of a military end user in China, Hong Kong, Russia, or Venezuela (\"Military End User\") or sells items that support or contribute to a Military End Use by a Military End User. Military End User includes any entity that is part of the national armed services (army, navy, marine, air force, or coast guard), as well as the national guard and national police, government intelligence or reconnaissance organizations, or any person or entity whose actions or functions are intended to support \"military end uses.\" \"Military End Uses\" includes use of an item to support or contribute to the operation, installation, maintenance, repair, overhaul, refurbishing, development, or production of military items. In addition, the Supplier will not divert or in any way utilize or sell products, materials, or technology/technical data/specifications supplied by or on behalf of Honeywell to Supplier under or in connection with the Agreement to/for any entity which is a Military End User or for Military End Uses by a Military End User; Supplier shall immediately notify Honeywell and cease all activities associated with the transaction in question if it knows or has a reasonable suspicion that such products, materials, technical data, plans, or specifications may be exported, reexported, or transferred to a Military End User or in support of a Military End Use by a Military End User; Supplier\\'s failure to comply with this provision will be deemed a material breach of the Agreement. Notwithstanding anything to the contrary in the Agreement, Honeywell may take any and all actions required to ensure full compliance with applicable export control laws without Honeywell incurring any liability.\\n\\n# 6. NOTICES AND POINTS OF CONTACT\\n\\na. \"Notices\" relating to this Contract must be in writing and delivered: (1) personally; (2) by a recognized overnight courier; (3) by certified first class mail, postage prepaid; or (4) by electronic transmission (email), with proof of delivery (each to the respective address appearing on the Purchase Order) to each Party\\'s designated Authorized Representative. A Notice will be deemed given (a) on the date delivered if delivered personally, (b) 5 business days after being placed in the mail, (c) one business day after being sent by overnight courier, or (d) on the date sent if sent by electronic transmission.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='26a264a5-df0f-41b6-beff-9cd7f3f3b573', embedding=None, metadata={'page_num': 4, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\nplaced in the custody of an overnight courier as specified, or (d) on the date of successful delivery when sent by email. For the purposes of this Contract; when a provision calls for Honeywell's written permission, consent, or signature, such permission, consent or signature must be given by a Honeywell's Authorized Representative.\\n\\nAll communications will be sent to the individuals set forth below or to such other individual as may be designated by a Party by giving written Notice to the other Party:\\n\\n# Procurement / Contracts Authorized Representatives\\n\\n|Name:|Rob Nelson|Tom Bunk|\\n|---|---|---|\\n|Title:|Principal Subcontracts Specialist|President|\\n|Address:|1300 W Warner Rd, Tempe, AZ 85284|38 Great Hill Rd, Naugatuck, CT 06770|\\n|Telephone:|480-592-1186|203-723-1404|\\n|E-Mail:|robert.nelson2@honeywell.com|tom.bunk@unitedavionicsinc.com|\\n\\n# 7. ORDER OF PRECEDENCE\\n\\nThe following order of precedence applies:\\n\\n1. Any U.S. Government provisions and clauses (e.g., FAR, DFARS or other agency supplements) included or incorporated by reference under this Contract;\\n2. Any document executed by both Parties after execution of this Contract that is expressly intended to amend or supersede the terms of this Contract;\\n3. This Contract;\\n4. The face of the Purchase Order issued pursuant to this Contract and any attachments included or incorporated by reference;\\n5. Other documents agreed to in writing by the Parties.\\n\\n# 8. PURCHASE COMMITMENT\\n\\nExcept as otherwise provided in this Contract, Supplier agrees to sell to Honeywell the Goods at prices as identified in Attachment 1 and Honeywell agrees to purchase such Goods at the prices and quantities described therein, subject to the U.S. Government TIGER III procurement requirements during the Contract Term.\\n\\nDelivery dates and locations will be made only as authorized by Purchase Orders. Such Purchase Orders are not separate contracts and are simply issued to confirm delivery dates, locations, and quantities. These Purchase Orders will be subject to the terms of this Contract and the general purchase order provisions in effect at the time of Purchase Order placement. In the event Supplier is unable to deliver the quantities specified on the dates in the Purchase Order, Supplier will provide Honeywell with an alternative delivery date in writing within 5 business days following issuance of the Purchase Order.\\n\\n# 10. PROGRAM MANAGEMENT\\n\\nProgram reviews may be held from time to time. The location of these reviews will be determined by the Parties based on subject matter. The topics of these reviews may include raw material and component part status, manufacturing status, production status, Supplier's current and future capacity assessments, inventory, Honeywell's and/or its customer's requirements, changes, forecasts and other issues pertinent to Supplier's performance under this Contract. Reviews will allow formal presentations and discussion of status reports as set forth above.\\n\\nHoneywell may request, and Supplier will support, Honeywell's customers holding periodic reviews with Supplier to ensure proper capacity margins are maintained and to develop and manage plans for future capacity requirements. Supplier will facilitate such reviews with its supply chain as required.\\n\\nWhen requested by Honeywell, Supplier will update and submit, as a minimum, monthly status reports or data requested by Honeywell using a method mutually agreed upon by Honeywell and Supplier. Honeywell has the right to impose more frequent reporting on Supplier to achieve Program objectives.\\n\\nWhen requested by Honeywell, Supplier will provide to Honeywell a manufacturing milestone chart identifying the major purchasing, planning and manufacturing operations for the applicable Goods.\\n\\n# 12. PRICE\\n\\nSupplier will furnish the Goods and Deliverables at the prices stated in Attachment 1. Prices are valid for all Honeywell purchases of Goods and Deliverables, including without limitation for follow-on spares and replacements. The prices stipulated herein are inclusive of all work to be performed under this Contract, unless otherwise specifically stated.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='ea85ea7b-0d36-4573-98de-2bfbf2f595e3', embedding=None, metadata={'page_num': 5, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\nin accordance with applicable FAR or DFAR, or equivalent requirements. In the event the U.S. Government determines any price to not be fair and reasonable under applicable FAR, DFAR, or equivalent requirements, Honeywell will decrement the price to a fair and reasonable price.\\n\\nSupplier agrees that all prices will be fair and reasonable as supported by documentation to substantiate fair and reasonable prices.\\n\\n# C\\n\\nIf the Parties are not able to negotiate a fair and reasonable price within 10 business days after receipt of written notice from the U.S. Government; then Supplier\\'s Vice President-General Manager for the business unit/segment that will perform the work required under this Contract and the appropriate Honeywell executive; each having the authority to bind their respective principal, will attempt to resolve the problem to their mutual satisfaction.\\n\\nIf Supplier\\'s Vice President-General Manager and Honeywell\\'s executive do not reach agreement on fair and reasonable price within 10 additional business days after escalation of this issue to the Vice President-General Manager and the Honeywell executive level, Honeywell will have the right to: 1) procure the Goods and Deliverables from an alternative supplier; but, before doing so, Honeywell will give Supplier a last right of refusal as follows: notwithstanding any other provision of this Contract; Purchase Order or related agreements, Honeywell may issue a request for quotation (\"RFQ\") to one (or more) suppliers in a competitive bid format using Supplier\\'s Confidential Information and/or Honeywell\\'s Confidential Information exclusively licensed to Supplier.\\n\\nWithin 10 business days of receiving responses from the other supplier(s) to whom it issued the RFQ, Honeywell will inform Supplier if Honeywell has received a more competitive and more compliant proposal from any other supplier. Supplier will have the opportunity to meet or exceed any final offers submitted by any other supplier to whom Honeywell issued the RFQ, provided that Supplier\\'s response must be received by Honeywell no more than 5 business days following Honeywell\\'s notification that it has received a more competitive offer.\\n\\nIf Honeywell determines, in its sole discretion, that Supplier\\'s response is as competitive as the other supplier\\'s, Honeywell will continue to procure from Supplier in accordance with the terms of this Contract as modified to reflect the new price. If Honeywell determines, in its sole discretion, Supplier\\'s response is not as competitive as the other suppliers\\', Honeywell will have the right to procure from the other supplier without recourse by Supplier. Honeywell\\'s determination in this matter will be final and not subject to dispute under this Contract.\\n\\n# d\\n\\nCertified Cost or Pricing Data or Other Than Certified Cost or Pricing Data: When submission of certified cost or pricing data or data other than certified cost or pricing data is required under applicable law or regulation in support of a government procurement and for use on or in connection with any U.S. Government solicitation(s), Supplier agrees to: (1) submit certified cost or pricing data or data other than certified cost or pricing data required to determine that the price is fair and reasonable as defined in Federal Acquisition Regulations; and (2) if requested, certify pursuant to Federal Acquisition Regulations that to the best of its knowledge and belief, the cost or pricing data is accurate, complete, and current as of the date of agreement on price or, if applicable, an earlier date agreed upon between the Parties that is as close as practicable to the date of agreement on price.\\n\\nIn the event Honeywell, U.S. Government, or its customer determines Supplier\\'s cost or pricing data requires certification pursuant to Federal Acquisition Regulations, the determination will be final and not subject to dispute under this Contract, and Supplier agrees to submit and certify its cost or pricing data as so required.\\n\\n# e\\n\\nIf Honeywell\\'s customer concludes that Supplier or its lower-tier suppliers: (1) submitted and/or certified cost or pricing data that is defective; (2) claimed an exception to submitting certified cost or pricing data and such exception is invalid; or if (3) U.S. Government alleges any of the foregoing; and as a result: (a) Honeywell\\'s contract price or fee is reduced; (b) Honeywell\\'s costs are determined to be unallowable; (c) any fines, penalties, or interest are assessed on Honeywell, or Honeywell incurs any other costs or damages; Honeywell may make a reduction of corresponding amounts (in whole or in part) in the costs and fee of this Contract or any other contract or purchase order with Supplier; and/or may demand payment (in whole or in part) of the corresponding amounts. Supplier shall promptly pay amounts so demanded. Such sums will not be considered allowable costs under any provision of the Contract.\\n\\nIn case of withholding(s), Honeywell may withhold the same amount from Supplier under this Contract.\\n\\n# f\\n\\nIf prices are not stated in this Contract, Supplier will furnish the Goods and Deliverables at the prices stated on the face of the Purchase Order; otherwise Supplier will offer its lowest prices, not to exceed the lowest price offered during the Contract Term, subject to written acceptance by Honeywell. Subject to Shipping Terms, Title and Risk of Loss provisions in the Purchase Order, the prices include all packaging; applicable taxes and other government charges including, but not limited to, all sales, use, or excise taxes; and all customs duties, fees, or charges.\\n\\nTo the extent that value added tax (or any equivalent tax) is properly chargeable on the supply to Honeywell of any Goods, Honeywell will pay the tax as an addition to payments otherwise due Supplier under this Contract, if Supplier provides to Honeywell a value-added tax (or equivalent tax) invoice. To the extent Honeywell has not received from Supplier all applicable forms regarding compliance with applicable tax law, Honeywell reserves the right to setoff from any payment to Supplier pursuant to this Contract those amounts that Honeywell, in its sole discretion, deems required to be withheld in order to comply with the tax laws of any applicable jurisdiction.\\n\\n# 13. THIRD PARTY COMMUNICATIONS\\n\\nSupplier is not authorized to communicate with any Honeywell customer or potential customer, including but not limited to aircraft original equipment manufacturers, aircraft owners, operators, and lessees, and dealers and distributors, regarding this Contract, without receipt of prior written approval from Honeywell.\\n\\n# 15. DATA PRIVACY\\n\\nHoneywell and Supplier may, in the course of performance of this Purchase Order, provide each other with certain Personal Data such as name and certain business contact details relating to individuals engaged by the other Party or its affiliates (\"Staff\") for the purposes of executing and performing the obligations under this Purchase Order and managing the business relationship between the Parties (\"Purposes\"). Any processing of Personal Data will be done in accordance with the terms of this Purchase Order.\\n\\n(v01-2021) Stand-Alone Government Program Contract\\n\\nPage 5 Honeywell\\n\\nHoneywell Confidential', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='8b8f068c-3fec-4cc2-87a4-5766d952b0e2', embedding=None, metadata={'page_num': 6, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\nStrictly necessary to provide the [Goods/ products and/or services] under this Purchase Order: Supplier will not access Personal Data controlled by Honeywell for the provision of the [Goods/ products and/or services] under this Purchase Order: Each Party will (a) implement all appropriate security measures to protect Personal Data provided by the other Party against accidental, unlawful, or unauthorized (i) destruction (ii) loss, (iii) alteration, (iv) disclosure, or (v) access (including remote access), (b) protect Personal Data beyond what is strictly necessary for the Purposes, (c) prior to any transfer of Personal Data, impose all obligations on third parties as required by this Purchase Order and Applicable Data Privacy Laws, and (d) securely delete such Personal Data once it is no longer required for the Purposes.\\n\\nEach Party shall be responsible for providing necessary information and notifications required by Applicable Data Privacy Laws to its respective Staff, including with respect to their rights and how to exercise them vis-a-vis the other Party: Where a Party\\'s Personal Data is transferred to a country that has not been deemed to provide an adequate level of protection for personal data by applicable laws, the other Party will either enter into or apply legally recognized international data transfer mechanisms, including (a) standard data protection clauses adopted or approved by the European Commission; (b) binding corporate rules which provide adequate safeguards, or (c) any other similar program or certification that is recognized as providing an adequate level of protection in accordance with Applicable Data Privacy Laws.\\n\\nIn addition to the requirements of this section, Supplier will comply with Honeywell\\'s Data Privacy Obligations for Suppliers posted at https://www.honeywell.com/who-we-are/integrity-and-compliance.\\n\\n# ENTIRE AGREEMENT\\n\\nThe exhibits, schedules and other attachments to this Contract are incorporated by reference. This Contract contains the entire agreement between the Parties and supersedes and replaces any prior or inconsistent agreements, negotiations, representations or promises, written or oral, between the Parties respecting the subject matter of this Contract. Neither Party has relied on any promises, inducements or representations by the other; except those expressly stated in this Contract.\\n\\n# IN WITNESS WHEREOF\\n\\nThe Parties have caused this Contract to be executed in English by their duly authorized representatives.\\n\\nHONEYWELL INTERNATIONAL INC, through its Aerospace Business Group\\n\\nUNITED AVIONICS INC.\\n\\nDocusigned by: Rob Nelson\\n\\nBy: E\"\"\"\\'\" ...Ie;3R83Nelson\\n\\nName: Rob Nelson\\n\\nTitle: Principal Subcontracts Specialist\\n\\nDate: 08-Apr-2021\\n\\nDocusigned by: Tom Bunk\\n\\nBy: [!-\"\"\"\"\"\\'\"T buk\\n\\nName: Tom Bunk\\n\\nTitle: President\\n\\nDate: 05-Apr-2021\\n\\nPlease return an executed copy of this Contract to Honeywell\\'s contact specified above.\\n\\nDS\\n\\nPage 6\\n\\n(v01-2021) Stand-Alone Government Program Contract\\n\\nHoneywell Confidential', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='f4447460-051b-4ef9-8145-9026555e78cb', embedding=None, metadata={'page_num': 7, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\n# ATTACHMENT\\n\\n# GOODS, DELIVERABLES, NON-RECURRING ENGINEERING, AND PRICES\\n\\n# 1 Production Prices\\n\\nProduction prices for the Goods are listed in TABLE 1.\\n\\n|Part Number|Description|Lead Time|Capacity|Monthly Quantity|Unit Price|Extended Price|Commercial Item|Competitive Award|Truthful Cost|\\n|---|---|---|---|---|---|---|---|---|---|\\n|3-300-952-01|HARNESS ASSY, ELECT|180|100|1208|$690.00|$833,520.00|Y|Data Applies|N|\\n|3-300-634-04|HARNESS ACCESS ELEC|180|100|883|$775.00|$684,325.00|Y|Data Applies|N|\\n|3-300-627-08|HARNESS ASSY, FUEL CONTROL, ELECTRICAL|180|100|800|$990.00|$792,000.00|Y|Data Applies|N|\\n|3-300-628-07|HARNESS ASSY, SPD PI|180|100|869|$300.00|$260,700.00|Y|Data Applies|N|\\n|3-170-930-01|STRAP GROUND ASSY QF|180|200|998|$300.00|$260,700.00|Y|Data Applies|N|\\n\\n# Option Year 1 (October 1, 2022 - September 30, 2023 Delivery Dates)\\n\\nto be exercised by Honeywell upon award by USG\\n\\n|Part Number|Description|Lead Time|Capacity|Monthly Quantity|Unit Price|Extended Price|Commercial Item|Competitive Award|Truthful Cost|\\n|---|---|---|---|---|---|---|---|---|---|\\n|3-300-952-01|HARNESS ASSY, ELECT|180|100|658|$690.00|$454,020.00|Y|Data Applies|N|\\n|3-300-634-04|HARNESS ACCESS ELEC|180|100|567|$775.00|$439,425.00|Y|Data Applies|N|\\n|3-300-627-08|HARNESS ASSY, FUEL CONTROL, ELECTRICAL|180|100|543|$990.00|$537,570.00|Y|Data Applies|N|\\n|3-300-628-07|HARNESS ASSY, SPD PI|180|100|465|$300.00|$139,500.00|Y|Data Applies|N|\\n|3-170-930-01|STRAP GROUND ASSY OF|180|200|515|$38.00|$19,570.00|Y|Data Applies|N|\\n\\n# Option Year 2 (October 1, 2023 - September 30, 2024 Delivery Dates)\\n\\nto be exercised by Honeywell upon award by USG\\n\\n|Part Number|Description|Lead Time|Capacity|Monthly Quantity|Unit Price|Extended Price|Commercial Item|Competitive Award|Truthful Cost|\\n|---|---|---|---|---|---|---|---|---|---|\\n|3-300-952-01|HARNESS ASSY, ELECT|180|100|640|$690.00|$441,600.00|Y|Data Applies|N|\\n|3-300-634-04|HARNESS ACCESS ELEC|180|100|640|$775.00|$427,025.00|N|Data Applies|N|\\n|3-300-627-08|HARNESS ASSY, FUEL CONTROL, ELECTRICAL|180|100|562|$990.00|$556,380.00|Y|Data Applies|N|\\n|3-300-628-07|HARNESS ASSY, SPD PI|180|100|562|$300.00|$134,100.00|Y|Data Applies|N|\\n|3-170-930-01|STRAP GROUND ASSY OF|180|200|496|$38.00|$18,848.00|Y|Data Applies|N|\\n\\n# Option Year 3 (October 1, 2024 - September 30, 2025 Delivery Dates)\\n\\nto be exercised by Honeywell upon award by USG\\n\\n|Part Number|Description|Lead Time|Capacity|Monthly Quantity|Unit Price|Extended Price|Commercial Item|Competitive Award|Truthful Cost|\\n|---|---|---|---|---|---|---|---|---|---|\\n|3-300-952-01|HARNESS ASSY, ELECT|180|100|624|$690.00|$430,560.00|Y|Data Applies|N|\\n|3-300-634-04|HARNESS ACCESS ELEC|180|100|540|$775.00|$418,500.00|N|Data Applies|N|\\n|3-300-627-08|HARNESS ASSY, FUEL CONTROL, ELECTRICAL|180|100|547|$990.00|$541,530.00|Y|Data Applies|N|\\n|3-300-628-07|HARNESS ASSY, SPD PI|180|100|403|$300.00|$120,900.00|Y|Data Applies|N|\\n|3-170-930-01|STRAP GROUND ASSY OF|180|200|475|$38.00|$18,050.00|Y|Data Applies|N|\\n\\nPage 7 Honeywell\\n\\nHoneywell Confidential\\n\\n(v01-2021) Stand-Alone Government Program Contract', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              "  TextNode(id_='21947339-3f70-4811-a9ba-75b067568411', embedding=None, metadata={'page_num': 8, 'paper_path': 'iclr_docs/1.3.2.6.2_Honeywell Long Term Contract_C14.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# Honeywell\\n\\n# STAND-ALONE GOVERNMENT PROGRAM CONTRACT\\n\\n# AEROSPACE SOURCING\\n\\n# THE POWER OF CONNECTED\\n\\n# ATTACHMENT 2\\n\\n# PRIME CONTRACT TERMS AND CONDITIONS\\n\\nThe following provisions apply to any Contract or Purchase Order if the Contract or Purchase Order is subject to any provision or regulation applicable to a United States Government Contract; Supplier must include in each lower-tier subcontract and purchase orders the appropriate flow down clauses as required by the FAR and FAR Supplement clauses included in this Contract or Purchase order:\\n\\n# 1. DEFINITIONS\\n\\nCapitalized terms that are used but not defined in these Supplemental Provisions have the meanings given them in the Contract.\\n\\n\"DFAR\" means the Defense Federal Acquisition Regulation Supplement to the FAR.\\n\\n\"FAR\" means the Federal Acquisition Regulation.\\n\\n# 2. AMENDMENTS REQUIRED BY PRIME CONTRACT\\n\\nSupplier agrees that upon request of Honeywell it will negotiate in good faith with Honeywell relative to amendments to this Contract to incorporate additional provisions herein or to change provisions hereof, as Honeywell may reasonably deem necessary to comply with the provisions of the applicable prime contractor with the provisions of amendments to such Prime Contract: If any such amendment to this Contract causes an increase or decrease in the cost of, or the time required for, performance under this Contract, an equitable adjustment will be made pursuant to the \"Changes\" clause of this Contract.\\n\\n# 3. PRESERVATION OF THE GOVERNMENT\\'S RIGHTS\\n\\nIf Honeywell furnishes designs, drawings, special tooling, equipment, engineering data, or other technical or Confidential Information (Furnished Items) which the Government owns or has the right to authorize the use of, nothing herein will be construed to mean that Honeywell acting on its own behalf, may modify or limit any rights the Government may have to authorize Supplier\\'s use of such Furnished Items in support of other U.S. Government prime contracts.\\n\\n# 4. DISPUTES\\n\\nIf a dispute relates to a matter that would give Honeywell recourse against the Federal Government under its contracts, the following provisions apply: Supplier will give Honeywell a fully supported written claim within five (5) years after the claim accrues, but no later than final payment under the order. Supplier will fully cooperate with Honeywell in prosecuting any such dispute and will be bound by the outcome unless Honeywell discontinues its prosecution of the dispute or does not afford Supplier an opportunity to continue to prosecute the dispute in Honeywell\\'s name.\\n\\nFor any claim that exceeds $100,000, Supplier shall provide a certification in the form and signed by the appropriate official of the Supplier as required by the \"Disputes\" clause, FAR 52.233-1 (May 2014), as directed by Honeywell.\\n\\n# 5. APPLICABLE LAW\\n\\nAny provision that is (i) incorporated in full text or by reference from the Federal Acquisition Regulation (\"FAR\"), or (ii) incorporated in full text or by reference from any agency regulation that implements or supplements the FAR, or (iii) that is substantially based on any such agency regulation or FAR provision, will be construed and interpreted according to the federal common law of government contracts as enunciated and applied by federal judicial bodies, Boards of Contract Appeals, and quasi-judicial agencies of the federal Government.\\n\\n# 6. CERTIFICATIONS AND REPRESENTATIONS\\n\\n52.219-1 Small Business Programs Representations (Oct 2014) - If the value of the order exceeds $10,000, SELLER shall submit the following certifications and representations:\\n\\n52.209-6 Protecting the Governments Interest When Subcontracting with Contractors Debarred, Suspended, or Proposed for Debarment (Oct 2015) - If the value of the order exceeds $35,000, SELLER shall submit the following certifications and representations:\\n\\n52.209-5 Certification Regarding Responsibility Matters (Oct 2015) - If the value of the order exceeds $150,000, SELLER shall submit the following certifications and representations:\\n\\n52.203-11 Certification and Disclosure Regarding Payments to Influence Certain Federal Transactions (Sep 2007)\\n\\n52.204-5 Women-Owned Business Other Than Small Business (Oct 2014) - If required, Supplier will submit the following certification at the time of submission of its offer/quote:\\n\\n52.225-2 Buy American Act Certificate (May 2014)\\n\\n52.222-18 Certification Regarding Knowledge of Child Labor for Listed End Products (Feb 2001) - Solicitations that are expected to exceed the micro-purchase threshold and are for the acquisition of end products (regardless of country of origin) of a type identified by country of origin on the List of Products Requiring Contractor Certification as to Forced or Indentured Child Labor; except solicitations for commercial items that include the provision at 52.212-3, Offeror Representations and Certifications - Commercial Items.\\n\\n52.222-22 Previous Contracts and Compliance Reports (Feb 1999) - Must be included when 52.222-21 and 52.222-26 are included.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "6e360a5c-29bd-4d86-9a21-f46013bab39a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e360a5c-29bd-4d86-9a21-f46013bab39a",
        "outputId": "b4d9a646-948f-461d-e6c5-d5e1a1ad9a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 12%|█▎        | 1/8 [00:00<00:03,  1.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 3/8 [00:01<00:01,  2.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 4/8 [00:01<00:01,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 62%|██████▎   | 5/8 [00:01<00:00,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:03<00:01,  1.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 7/8 [00:05<00:01,  1.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 8/8 [00:05<00:00,  1.53it/s]\n"
          ]
        }
      ],
      "source": [
        "sections_dict = asyncio_run(acreate_sections(text_nodes_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "d930f0e5-5295-46b0-b54b-e2da4fb25fe5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d930f0e5-5295-46b0-b54b-e2da4fb25fe5",
        "outputId": "3226c1e7-abe0-421e-9bf1-88754249d2ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SectionOutput(section_name='1', section_title='DEFINITIONS', start_page_number=3, is_subsection=False, description='# 1. DEFINITIONS'),\n",
              " SectionOutput(section_name='2', section_title='SCOPE', start_page_number=3, is_subsection=False, description='# 2. SCOPE'),\n",
              " SectionOutput(section_name='3', section_title='CONTRACT TERM', start_page_number=3, is_subsection=False, description='# 3. CONTRACT TERM'),\n",
              " SectionOutput(section_name='4', section_title='DEFENSE PRIORITIES AND ALLOCATIONS SYSTEM (DPAS) RATING', start_page_number=3, is_subsection=False, description='# 4. DEFENSE PRIORITIES AND ALLOCATIONS SYSTEM (DPAS) RATING'),\n",
              " SectionOutput(section_name='5', section_title='NON-MILITARY END USER AND END USE CERTIFICATION (MEU RULE)', start_page_number=3, is_subsection=False, description='# 5. NON-MILITARY END USER AND END USE CERTIFICATION (MEU RULE)'),\n",
              " SectionOutput(section_name='6', section_title='NOTICES AND POINTS OF CONTACT', start_page_number=3, is_subsection=False, description='# 6. NOTICES AND POINTS OF CONTACT'),\n",
              " SectionOutput(section_name='7', section_title='ORDER OF PRECEDENCE', start_page_number=4, is_subsection=False, description='# 7. ORDER OF PRECEDENCE'),\n",
              " SectionOutput(section_name='8', section_title='PURCHASE COMMITMENT', start_page_number=4, is_subsection=False, description='# 8. PURCHASE COMMITMENT'),\n",
              " SectionOutput(section_name='10', section_title='PROGRAM MANAGEMENT', start_page_number=4, is_subsection=False, description='# 10. PROGRAM MANAGEMENT'),\n",
              " SectionOutput(section_name='12', section_title='PRICE', start_page_number=4, is_subsection=False, description='# 12. PRICE'),\n",
              " SectionOutput(section_name='13', section_title='THIRD PARTY COMMUNICATIONS', start_page_number=5, is_subsection=False, description='# 13. THIRD PARTY COMMUNICATIONS'),\n",
              " SectionOutput(section_name='15', section_title='DATA PRIVACY', start_page_number=5, is_subsection=False, description='# 15. DATA PRIVACY'),\n",
              " SectionOutput(section_name='1', section_title='DEFINITIONS', start_page_number=8, is_subsection=False, description='# 1. DEFINITIONS'),\n",
              " SectionOutput(section_name='2', section_title='AMENDMENTS REQUIRED BY PRIME CONTRACT', start_page_number=8, is_subsection=False, description='# 2. AMENDMENTS REQUIRED BY PRIME CONTRACT'),\n",
              " SectionOutput(section_name='3', section_title=\"PRESERVATION OF THE GOVERNMENT'S RIGHTS\", start_page_number=8, is_subsection=False, description=\"# 3. PRESERVATION OF THE GOVERNMENT'S RIGHTS\"),\n",
              " SectionOutput(section_name='4', section_title='DISPUTES', start_page_number=8, is_subsection=False, description='# 4. DISPUTES'),\n",
              " SectionOutput(section_name='5', section_title='APPLICABLE LAW', start_page_number=8, is_subsection=False, description='# 5. APPLICABLE LAW'),\n",
              " SectionOutput(section_name='6', section_title='CERTIFICATIONS AND REPRESENTATIONS', start_page_number=8, is_subsection=False, description='# 6. CERTIFICATIONS AND REPRESENTATIONS')]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "sections_dict[\"1.3.2.6.2_Honeywell Long Term Contract_C14.pdf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "8c6f237b-df2a-4d9e-91bf-b0bbb88ef183",
      "metadata": {
        "id": "8c6f237b-df2a-4d9e-91bf-b0bbb88ef183"
      },
      "outputs": [],
      "source": [
        "# [Optional] SAVE\n",
        "import pickle\n",
        "\n",
        "pickle.dump(sections_dict, open(\"sections_dict.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "7497b614-250e-4f3e-8940-b361996a00b6",
      "metadata": {
        "id": "7497b614-250e-4f3e-8940-b361996a00b6"
      },
      "outputs": [],
      "source": [
        "# [Optional] LOAD\n",
        "sections_dict = pickle.load(open(\"sections_dict.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b01141-d9c1-424c-937a-8707867180b1",
      "metadata": {
        "id": "28b01141-d9c1-424c-937a-8707867180b1"
      },
      "source": [
        "#### Annotate each chunk with the section metadata\n",
        "\n",
        "In the section above we've extracted out a TOC of all sections/subsections and their page numbers. Given this we can just do one forward pass through all the chunks, and annotate them with the section they correspond to (e.g. the section/subsection with the highest page number less than the page number of the chunk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "38133abe-7800-424a-9259-71df6d154d31",
      "metadata": {
        "id": "38133abe-7800-424a-9259-71df6d154d31"
      },
      "outputs": [],
      "source": [
        "def annotate_chunks_with_sections(chunks, sections):\n",
        "    main_sections = [s for s in sections if not s.is_subsection]\n",
        "    # subsections include the main sections too (some sections have no subsections etc.)\n",
        "    sub_sections = sections\n",
        "\n",
        "    main_section_idx, sub_section_idx = 0, 0\n",
        "    for idx, c in enumerate(chunks):\n",
        "        cur_page = c.metadata[\"page_num\"]\n",
        "        while (\n",
        "            main_section_idx + 1 < len(main_sections)\n",
        "            and main_sections[main_section_idx + 1].start_page_number <= cur_page\n",
        "        ):\n",
        "            main_section_idx += 1\n",
        "        while (\n",
        "            sub_section_idx + 1 < len(sub_sections)\n",
        "            and sub_sections[sub_section_idx + 1].start_page_number <= cur_page\n",
        "        ):\n",
        "            sub_section_idx += 1\n",
        "\n",
        "        cur_main_section = main_sections[main_section_idx]\n",
        "        cur_sub_section = sub_sections[sub_section_idx]\n",
        "\n",
        "        c.metadata[\"section_id\"] = cur_main_section.get_section_id()\n",
        "        c.metadata[\"sub_section_id\"] = cur_sub_section.get_section_id()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "d125b0c0-acb0-4f56-9ef3-f06d452ae3cd",
      "metadata": {
        "id": "d125b0c0-acb0-4f56-9ef3-f06d452ae3cd"
      },
      "outputs": [],
      "source": [
        "for paper_path, text_nodes in text_nodes_dict.items():\n",
        "    sections = sections_dict[paper_path]\n",
        "    annotate_chunks_with_sections(text_nodes, sections)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ab80d2-cac4-417d-aaac-7ea9dfed49f7",
      "metadata": {
        "id": "b1ab80d2-cac4-417d-aaac-7ea9dfed49f7"
      },
      "source": [
        "You can choose to save these nodes if you'd like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "2272ae05-89f6-46a9-9b9f-915e15908128",
      "metadata": {
        "id": "2272ae05-89f6-46a9-9b9f-915e15908128"
      },
      "outputs": [],
      "source": [
        "# SAVE\n",
        "import pickle\n",
        "\n",
        "pickle.dump(text_nodes_dict, open(\"iclr_text_nodes.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ebf0173-af45-4fae-aca4-2ceb266f8357",
      "metadata": {
        "id": "8ebf0173-af45-4fae-aca4-2ceb266f8357"
      },
      "source": [
        "**LOAD**: If you've already saved nodes, run the below cell to load from an existing file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "c1e5425b-4872-47b3-86f5-f6a068788a2b",
      "metadata": {
        "id": "c1e5425b-4872-47b3-86f5-f6a068788a2b"
      },
      "outputs": [],
      "source": [
        "# LOAD\n",
        "import pickle\n",
        "\n",
        "text_nodes_dict = pickle.load(open(\"iclr_text_nodes.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "642e90f1-1d32-4925-b37d-2af8a0ca9712",
      "metadata": {
        "id": "642e90f1-1d32-4925-b37d-2af8a0ca9712"
      },
      "outputs": [],
      "source": [
        "all_text_nodes = []\n",
        "for paper_path, text_nodes in text_nodes_dict.items():\n",
        "    all_text_nodes.extend(text_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "8d7b566b-5ec1-4e49-b4d4-e863af2aabc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d7b566b-5ec1-4e49-b4d4-e863af2aabc6",
        "outputId": "6a5f1a2b-b3e6-4039-dcd7-0d1f874dd433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "len(all_text_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03a4de3-39ce-40c3-b37b-b6bbc597ddb1",
      "metadata": {
        "id": "d03a4de3-39ce-40c3-b37b-b6bbc597ddb1"
      },
      "source": [
        "### Build Indexes\n",
        "\n",
        "Once the text nodes are ready, we feed into our vector store index abstraction, which will index these nodes into a simple in-memory vector store (of course, you should definitely check out our 40+ vector store integrations!)\n",
        "\n",
        "Besides vector indexing, we **also** store a mapping of paper path to the summary index. This allows us to perform document-level retrieval - retrieve all chunks relevant to a given document."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-chroma"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N94fVGo3mMlg",
        "outputId": "715fb488-a76a-4752-c499-5e398aa34dd2"
      },
      "id": "N94fVGo3mMlg",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-chroma\n",
            "  Downloading llama_index_vector_stores_chroma-0.4.0-py3-none-any.whl.metadata (696 bytes)\n",
            "Collecting chromadb>=0.5.17 (from llama-index-vector-stores-chroma)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-chroma) (0.12.2)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.2)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.68.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.13.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (4.0.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.1.0)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.9.11)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b2)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.26.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.23.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.16.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Downloading llama_index_vector_stores_chroma-0.4.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=71d9b95d2a8439e4c5a9b338014c66e4f1537cde456a8a31da7060d1d3932a18\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, llama-index-vector-stores-chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 llama-index-vector-stores-chroma-0.4.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "add64e3e-12df-4d5a-beba-b3018325e15b",
      "metadata": {
        "id": "add64e3e-12df-4d5a-beba-b3018325e15b"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "persist_dir = \"storage_chroma\"\n",
        "\n",
        "vector_store = ChromaVectorStore.from_params(\n",
        "    collection_name=\"text_nodes\", persist_dir=persist_dir\n",
        ")\n",
        "index = VectorStoreIndex.from_vector_store(vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e46583a-6c6b-4a5e-b78a-d06721ae7d1c",
      "metadata": {
        "id": "1e46583a-6c6b-4a5e-b78a-d06721ae7d1c"
      },
      "source": [
        "**NOTE**: Don't run the block below if you've already inserted the nodes. Only run if it's your first time!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "9777f302-699a-4417-99b8-2be4e7cd60f5",
      "metadata": {
        "id": "9777f302-699a-4417-99b8-2be4e7cd60f5"
      },
      "outputs": [],
      "source": [
        "index.insert_nodes(all_text_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46f14ff-45b1-41f4-84e2-a6e5d6637809",
      "metadata": {
        "id": "d46f14ff-45b1-41f4-84e2-a6e5d6637809"
      },
      "source": [
        "## Setup Dynamic, Section-Level Retrieval\n",
        "\n",
        "We now setup a retriever that will allow us to retrieve an entire contiguous section in a document, instead of a chunk of it. This is useful for preserving the entire context within a doc.\n",
        "\n",
        "- Step 1: Do chunk-level retrieval to find the relevant chunks.\n",
        "- Step 2: For each chunk, identify the section that it corresponds to.\n",
        "- Step 3: Do a second retrieval pass using metadata filters to find the entire contiguous section that matches the chunk, and return that as a continguous node.\n",
        "- Step 4: Feed the contiguous sections into the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652cb067-da39-42cb-a303-faa346f72e13",
      "metadata": {
        "id": "652cb067-da39-42cb-a303-faa346f72e13"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "253f0c57-f5b4-4dbd-a0a0-62a42bd5bbdc",
      "metadata": {
        "id": "253f0c57-f5b4-4dbd-a0a0-62a42bd5bbdc"
      },
      "outputs": [],
      "source": [
        "chunk_retriever = index.as_retriever(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "b0a564cb-bfdb-48a5-9d67-10390c3a6c28",
      "metadata": {
        "id": "b0a564cb-bfdb-48a5-9d67-10390c3a6c28"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores.types import (\n",
        "    VectorStoreInfo,\n",
        "    VectorStoreQuerySpec,\n",
        "    MetadataInfo,\n",
        "    MetadataFilters,\n",
        "    FilterCondition,\n",
        ")\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "\n",
        "\n",
        "def section_retrieve(query: str, verbose: bool = False) -> List[NodeWithScore]:\n",
        "    \"\"\"Retrieve sections.\"\"\"\n",
        "    if verbose:\n",
        "        print(f\">> Identifying the right sections to retrieve\")\n",
        "    chunk_nodes = chunk_retriever.retrieve(query)\n",
        "\n",
        "    all_section_nodes = {}\n",
        "    for node in chunk_nodes:\n",
        "        section_id = node.node.metadata[\"section_id\"]\n",
        "        if verbose:\n",
        "            print(f\">> Retrieving section: {section_id}\")\n",
        "        filters = MetadataFilters.from_dicts(\n",
        "            [\n",
        "                {\"key\": \"section_id\", \"value\": section_id, \"operator\": \"==\"},\n",
        "                {\n",
        "                    \"key\": \"paper_path\",\n",
        "                    \"value\": node.node.metadata[\"paper_path\"],\n",
        "                    \"operator\": \"==\",\n",
        "                },\n",
        "            ],\n",
        "            condition=FilterCondition.AND,\n",
        "        )\n",
        "\n",
        "        # TODO: make node_ids not positional\n",
        "        section_nodes_raw = index.vector_store.get_nodes(node_ids=None, filters=filters)\n",
        "        section_nodes = [NodeWithScore(node=n) for n in section_nodes_raw]\n",
        "        # order and consolidate nodes\n",
        "        section_nodes_sorted = sorted(\n",
        "            section_nodes, key=lambda x: x.metadata[\"page_num\"]\n",
        "        )\n",
        "\n",
        "        all_section_nodes.update({n.id_: n for n in section_nodes_sorted})\n",
        "    return all_section_nodes.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "f721e770-ce4c-4511-96d5-8a89d16c7281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "f721e770-ce4c-4511-96d5-8a89d16c7281",
        "outputId": "953853bd-52fe-4c85-aaa0-f0ec7350657f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Identifying the right sections to retrieve\n",
            ">> Retrieving section: 1: DEFINITIONS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected IDs to be a non-empty list, got 0 IDs in get.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36m_validate_and_prepare_get_request\u001b[0;34m(self, ids, where, where_document, include)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpacked_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mvalidate_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpacked_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/types.py\u001b[0m in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected IDs to be a non-empty list, got {len(ids)} IDs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-489dab5aedf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nodes = section_retrieve(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"list all sections about product production\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-120-87ce821342a2>\u001b[0m in \u001b[0;36msection_retrieve\u001b[0;34m(query, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# TODO: make node_ids not positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msection_nodes_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0msection_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNodeWithScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msection_nodes_raw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# order and consolidate nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/vector_stores/chroma/base.py\u001b[0m in \u001b[0;36mget_nodes\u001b[0;34m(self, node_ids, filters)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/vector_stores/chroma/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, limit, where, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     ) -> VectorStoreQueryResult:\n\u001b[0;32m--> 432\u001b[0;31m         results = self._collection.get(\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/Collection.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, ids, where, limit, offset, where_document, include)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         get_request = self._validate_and_prepare_get_request(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{str(e)} in {name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{str(e)} in {name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36m_validate_and_prepare_get_request\u001b[0;34m(self, ids, where, where_document, include)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpacked_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mvalidate_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpacked_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mvalidate_filter_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/types.py\u001b[0m in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected IDs to be a list, got {type(ids).__name__} as IDs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected IDs to be a non-empty list, got {len(ids)} IDs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0mdups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs in get."
          ]
        }
      ],
      "source": [
        "nodes = section_retrieve(\n",
        "    \"list all sections about product production\", verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "e99eaa71-7d93-40c0-bba0-a9c983a6cbd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "e99eaa71-7d93-40c0-bba0-a9c983a6cbd3",
        "outputId": "960b10f3-88ab-4adb-cd72-e118fed06476"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nodes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-c5496652592e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nodes' is not defined"
          ]
        }
      ],
      "source": [
        "for n in nodes:\n",
        "    print(n.node.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "509de5ae-4d51-4b39-b67e-698cb84acd73",
      "metadata": {
        "id": "509de5ae-4d51-4b39-b67e-698cb84acd73",
        "outputId": "74e990f3-e6b2-4929-f9d9-93d9bc00b6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Identifying the right sections to retrieve\n",
            ">> Retrieving section: F: ADDITIONAL RESULTS\n",
            ">> Retrieving section: 5: EXPERIMENTS\n",
            ">> Retrieving section: F: ADDITIONAL RESULTS\n"
          ]
        }
      ],
      "source": [
        "nodes = section_retrieve(\n",
        "    \"Give me details of all additional experimental results in the Metra paper\",\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db64a838-5f19-46e0-b874-859a125f8dcd",
      "metadata": {
        "id": "db64a838-5f19-46e0-b874-859a125f8dcd",
        "outputId": "5edd609f-6acf-4fa9-e807-aa0619b1ea79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page_num': 21, 'paper_path': 'iclr_docs/metra.pdf', 'section_id': 'F: ADDITIONAL RESULTS', 'sub_section_id': 'F.1: FULL QUALITATIVE RESULTS'}\n",
            "{'page_num': 22, 'paper_path': 'iclr_docs/metra.pdf', 'section_id': 'F: ADDITIONAL RESULTS', 'sub_section_id': 'F.4: Additional Baselines'}\n",
            "{'page_num': 6, 'paper_path': 'iclr_docs/metra.pdf', 'section_id': '5: EXPERIMENTS', 'sub_section_id': '5: EXPERIMENTS'}\n",
            "{'page_num': 7, 'paper_path': 'iclr_docs/metra.pdf', 'section_id': '5: EXPERIMENTS', 'sub_section_id': '5.2: QUALITATIVE COMPARISON'}\n",
            "{'page_num': 8, 'paper_path': 'iclr_docs/metra.pdf', 'section_id': '5: EXPERIMENTS', 'sub_section_id': '5.3: QUANTITATIVE COMPARISON'}\n"
          ]
        }
      ],
      "source": [
        "for n in nodes:\n",
        "    print(n.node.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67303e6-ec65-499b-85bb-8189d220b466",
      "metadata": {
        "id": "d67303e6-ec65-499b-85bb-8189d220b466"
      },
      "source": [
        "### Try out Section-Level Retrieval as a Full RAG Pipeline\n",
        "\n",
        "Now that we've defined the retriever, we can plug the retrieved results into an LLM to create a full RAG pipeline!\n",
        "\n",
        "Our response synthesizers help handle dumping context into the LLM prompt window while accounting for context window limitations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb382809-d38e-4f03-bf26-6e1bf0d98df6",
      "metadata": {
        "id": "bb382809-d38e-4f03-bf26-6e1bf0d98df6"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import CustomQueryEngine\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, BaseSynthesizer\n",
        "\n",
        "\n",
        "class SectionRetrieverRAGEngine(CustomQueryEngine):\n",
        "    \"\"\"RAG Query Engine.\"\"\"\n",
        "\n",
        "    synthesizer: BaseSynthesizer\n",
        "    verbose: bool = True\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(synthesizer=TreeSummarize(llm=llm))\n",
        "\n",
        "    def custom_query(self, query_str: str):\n",
        "        nodes = section_retrieve(query_str, verbose=self.verbose)\n",
        "        response_obj = self.synthesizer.synthesize(query_str, nodes)\n",
        "        return response_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "426d9426-a145-4f50-ad37-4dd82b5c7ae8",
      "metadata": {
        "id": "426d9426-a145-4f50-ad37-4dd82b5c7ae8"
      },
      "outputs": [],
      "source": [
        "query_engine = SectionRetrieverRAGEngine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ec3f98-7181-4850-8b37-1e0aa751bf54",
      "metadata": {
        "id": "d1ec3f98-7181-4850-8b37-1e0aa751bf54",
        "outputId": "984edcff-5d0e-4a5a-dc35-2b7bfe1142a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Identifying the right sections to retrieve\n",
            ">> Retrieving section: A: BENCHMARK DETAILS\n",
            ">> Retrieving section: 5: RESULTS\n",
            ">> Retrieving section: A: BENCHMARK DETAILS\n",
            "In SWEBench, difficulty correlates with context length in a way that as the total context length increases, model performance tends to drop. This is observed across various models, including Claude 2, which shows a significant decrease in performance with longer context lengths. The models often struggle to localize the problematic code that needs updating when presented with a lot of code that may not be directly related to the issue at hand. This suggests that models can become distracted by additional context, which aligns with findings from other studies indicating that models may be sensitive to the relative location of target sequences. Even when increasing the maximum context size improves recall with respect to the oracle files, performance still drops, indicating that models are ineffective at localizing the necessary code changes.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"Tell me more about how difficulty correlates with context length in SWEBench\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483f5615-ab58-4bc7-968b-7a9e116756e1",
      "metadata": {
        "id": "483f5615-ab58-4bc7-968b-7a9e116756e1",
        "outputId": "bc353fcf-1152-4e83-b87f-c6f8d8886a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Identifying the right sections to retrieve\n",
            ">> Retrieving section: A: BENCHMARK DETAILS\n",
            ">> Retrieving section: 2: BENCHMARK CONSTRUCTION\n",
            ">> Retrieving section: A: BENCHMARK DETAILS\n",
            "SWE-bench is a benchmark designed to evaluate language models in a realistic software engineering setting by using GitHub issues and pull requests from popular repositories. The benchmark involves generating a pull request that addresses a given issue and passes related tests. The construction of SWE-bench involves a three-stage pipeline:\n",
            "\n",
            "1. **Repo Selection and Data Scraping**: Pull requests are collected from 12 popular open-source Python repositories on GitHub, resulting in approximately 90,000 PRs. These repositories are chosen for their better maintenance, clear contributor guidelines, and comprehensive test coverage.\n",
            "\n",
            "2. **Attribute-Based Filtering**: Candidate tasks are created by selecting merged PRs that resolve a GitHub issue and contribute tests. This indicates that the user likely added tests to verify the resolution of the issue.\n",
            "\n",
            "3. **Execution-Based Filtering**: For each candidate task, the PR's test content is applied, and test results are logged before and after applying the PR's other content. Tasks are filtered out if they do not have at least one test that changes from fail to pass or if they result in installation or runtime errors.\n",
            "\n",
            "The benchmark is designed to be extensible, allowing for updates with new task instances as new language models are released. It includes a robust framework for execution-based evaluation, ensuring that generated solutions can be verified by running unit tests. SWE-bench also provides a training dataset, SWE-bench-train, and fine-tuned models like SWE-Llama 7b and 13b, which are based on the CodeLlama model. These models are evaluated on their ability to resolve issues, with SWE-Llama 13b showing competitive performance in some settings.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"Give me a full overview of the benchmark details in SWE Bench\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d747bf8-0ed2-4c10-8108-9d0e8d53a4fb",
      "metadata": {
        "id": "6d747bf8-0ed2-4c10-8108-9d0e8d53a4fb",
        "outputId": "c38655b9-dd1b-49d9-cf8d-bb1b2e3f46e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page_num': 15, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.1: HIGH LEVEL OVERVIEW'}\n",
            "{'page_num': 16, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.2: CONSTRUCTION PROCESS'}\n",
            "{'page_num': 17, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.2: CONSTRUCTION PROCESS'}\n",
            "{'page_num': 18, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.3: Execution-Based Validation'}\n",
            "{'page_num': 19, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.3: Execution-Based Validation'}\n",
            "{'page_num': 20, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.5: Evaluation Test Set Characterization'}\n",
            "{'page_num': 21, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.5: Evaluation Test Set Characterization'}\n",
            "{'page_num': 22, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.5: Evaluation Test Set Characterization'}\n",
            "{'page_num': 23, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': 'A: BENCHMARK DETAILS', 'sub_section_id': 'A.6: DEVELOPMENT SET CHARACTERIZATION'}\n",
            "{'page_num': 2, 'paper_path': 'iclr_docs/swebench.pdf', 'section_id': '2: BENCHMARK CONSTRUCTION', 'sub_section_id': '2: BENCHMARK CONSTRUCTION'}\n"
          ]
        }
      ],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b11a23-df6a-4d83-b35c-691bb4d125c0",
      "metadata": {
        "id": "62b11a23-df6a-4d83-b35c-691bb4d125c0",
        "outputId": "0118b99b-c2a2-4cfa-b798-62f213530eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Identifying the right sections to retrieve\n",
            ">> Retrieving section: F: ADDITIONAL RESULTS\n",
            ">> Retrieving section: 5: EXPERIMENTS\n",
            ">> Retrieving section: F: ADDITIONAL RESULTS\n",
            "The additional experimental results in the METRA paper include several key findings:\n",
            "\n",
            "1. **Full Qualitative Results**: METRA discovers diverse locomotion behaviors across different environments, including state-based Ant and HalfCheetah, and pixel-based Quadruped and Humanoid. The results are consistent across multiple random seeds, indicating robustness in behavior discovery.\n",
            "\n",
            "2. **Latent Space Visualization**: METRA effectively captures the most temporally spread-out dimensions in the state space, such as x-y coordinates, in its latent space. This is demonstrated in both state-based and pixel-based environments, with higher-dimensional latent spaces capturing more diverse behaviors.\n",
            "\n",
            "3. **Ablation Study of Latent Space Sizes**: The study shows that increasing the size of the latent space generally enhances the diversity of skills learned by METRA. Different dimensions of continuous and discrete skills were tested on Ant and HalfCheetah.\n",
            "\n",
            "4. **Comparison with Additional Baselines**: METRA was compared with DGPO, a method focused on finding diverse behaviors that maximize task rewards. The comparison was conducted in a controlled Markov process setting without external rewards, using only intrinsic rewards.\n",
            "\n",
            "These results highlight METRA's ability to discover diverse and meaningful behaviors in various environments, its effective use of latent spaces, and its performance relative to other methods.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"Give me details of all additional experimental results in the Metra paper\"\n",
        ")\n",
        "print(str(response))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v3",
      "language": "python",
      "name": "llama_index_v3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}